2022-09-01 10:36:02 | INFO | fairseq.distributed_utils | distributed init (rank 1): env://
2022-09-01 10:36:02 | INFO | fairseq.distributed_utils | distributed init (rank 2): env://
2022-09-01 10:36:02 | INFO | fairseq.distributed_utils | distributed init (rank 0): env://
2022-09-01 10:36:02 | INFO | fairseq.distributed_utils | distributed init (rank 1): env://
2022-09-01 10:36:05 | INFO | fairseq.distributed_utils | initialized host gpu3 as rank 0
2022-09-01 10:36:05 | INFO | fairseq.distributed_utils | initialized host gpu3 as rank 1
2022-09-01 10:36:05 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='0.9,0.98', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_immt_tiny', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, broadcast_buffers=False, bucket_cap_mb=25, caption_file=None, clip_norm=25, cpu=False, criterion='label_smoothed_immt_cross_entropy', cross_self_attention=False, curriculum=0, data='../data/mscoco17/en-de/inverseKD/pre', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=128, decoder_embed_path=None, decoder_ffn_embed_dim=256, decoder_input_dim=128, decoder_layerdrop=0, decoder_layers=4, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=128, device_id=0, disable_validation=False, dist_func='l2', distributed_backend='nccl', distributed_init_method='env://', distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=2, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=128, encoder_embed_path=None, encoder_ffn_embed_dim=256, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=True, fix_batches_to_gpus=False, fix_gen_cnn=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, grain='model', image_suffix='image', keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_file=None, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format='json', log_interval=100, loss1_coeff=1.0, loss2_coeff=1.0, lr=[0.004], lr_scheduler='inverse_sqrt', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=150000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, multimodal_model_type='graphtransformer', no_cross_attention=False, no_double_encoder=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_src_positional_embeddings=False, no_tgt_positional_embeddings=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pretrained_cnn='resnet50', required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='../checkpoints/mscoco17/en-de/inverseKD_res_m_l2', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation_immt', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_nonlinear_projection=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=2000, weight_decay=0.0)
2022-09-01 10:36:05 | INFO | fairseq.tasks.translation_immt | [en] dictionary: 13448 types
2022-09-01 10:36:05 | INFO | fairseq.tasks.translation_immt | [de] dictionary: 13448 types
2022-09-01 10:36:05 | INFO | fairseq.data.data_utils | loaded 25014 examples from: ../data/mscoco17/en-de/inverseKD/pre/valid.en-de.en
2022-09-01 10:36:05 | INFO | fairseq.data.data_utils | loaded 25014 examples from: ../data/mscoco17/en-de/inverseKD/pre/valid.en-de.de
2022-09-01 10:36:11 | INFO | fairseq.data.data_utils | loaded 25014 examples from: ../data/mscoco17/en-de/inverseKD/pre/valid.image.en-de
2022-09-01 10:36:11 | INFO | fairseq.tasks.translation_immt | ../data/mscoco17/en-de/inverseKD/pre valid en-de 25014 examples
Built pre-trained CNN resnet50 in 3 seconds.
Built pre-trained CNN resnet50 in 2 seconds.
save_dir:../checkpoints/mscoco17/en-de/inverseKD_res_m_l2 2022-09-01 10:36:18 | INFO | fairseq_cli.train | TransformerIMMTModel(
  (encoder): TransformerIMMTEncoder(
    (embed_tokens): Embedding(13448, 128, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerIMMTEncoderLayer(
        (self_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerIMMTEncoderLayer(
        (self_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerIMMTEncoderLayer(
        (self_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerIMMTEncoderLayer(
        (self_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (encoder_image): ImageLocalFeaturesProjector(
      (layers): Sequential(
        (0): View()
        (1): Linear(in_features=2048, out_features=128, bias=True)
        (2): Dropout(p=0.3, inplace=False)
      )
    )
  )
  (decoder): TransformerIMMTDecoder(
    (embed_tokens): Embedding(13448, 128, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerIMMTDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerIMMTDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerIMMTDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerIMMTDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
)
2022-09-01 10:36:18 | INFO | fairseq_cli.train | model transformer_immt_tiny, criterion LabelSmoothedImmtCrossEntropyCriterion
2022-09-01 10:36:18 | INFO | fairseq_cli.train | num. model params: 3309184 (num. trained: 3309184)
2022-09-01 10:36:18 | INFO | fairseq_cli.train | training on 2 GPUs
2022-09-01 10:36:18 | INFO | fairseq_cli.train | max tokens per GPU = 1024 and max sentences per GPU = None
2022-09-01 10:36:18 | INFO | fairseq.trainer | no existing checkpoint found ../checkpoints/mscoco17/en-de/inverseKD_res_m_l2/checkpoint_last.pt
2022-09-01 10:36:18 | INFO | fairseq.trainer | loading train data for epoch 1
2022-09-01 10:36:18 | INFO | fairseq.data.data_utils | loaded 591753 examples from: ../data/mscoco17/en-de/inverseKD/pre/train.en-de.en
2022-09-01 10:36:18 | INFO | fairseq.data.data_utils | loaded 591753 examples from: ../data/mscoco17/en-de/inverseKD/pre/train.en-de.de
Built pre-trained CNN resnet50 in 3 seconds.
Built pre-trained CNN resnet50 in 2 seconds.
save_dir:../checkpoints/mscoco17/en-de/inverseKD_res_m_l2 *****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2022-09-01 10:38:15 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='0.9,0.98', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_immt_tiny', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, broadcast_buffers=False, bucket_cap_mb=25, caption_file=None, clip_norm=25, cpu=False, criterion='label_smoothed_immt_cross_entropy', cross_self_attention=False, curriculum=0, data='../data/mscoco17/en-de/inverseKD/pre', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=128, decoder_embed_path=None, decoder_ffn_embed_dim=256, decoder_input_dim=128, decoder_layerdrop=0, decoder_layers=4, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=128, device_id=0, disable_validation=False, dist_func='l2', distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=128, encoder_embed_path=None, encoder_ffn_embed_dim=256, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=True, fix_batches_to_gpus=False, fix_gen_cnn=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, grain='model', image_suffix='image', keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_file=None, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format='json', log_interval=100, loss1_coeff=1.0, loss2_coeff=1.0, lr=[0.004], lr_scheduler='inverse_sqrt', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=150000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, multimodal_model_type='graphtransformer', no_cross_attention=False, no_double_encoder=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_src_positional_embeddings=False, no_tgt_positional_embeddings=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pretrained_cnn='resnet50', required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='../checkpoints/mscoco17/en-de/inverseKD_res_m_l2', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation_immt', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_nonlinear_projection=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=2000, weight_decay=0.0)
2022-09-01 10:38:15 | INFO | fairseq.tasks.translation_immt | [en] dictionary: 13448 types
2022-09-01 10:38:15 | INFO | fairseq.tasks.translation_immt | [de] dictionary: 13448 types
2022-09-01 10:38:16 | INFO | fairseq.data.data_utils | loaded 25014 examples from: ../data/mscoco17/en-de/inverseKD/pre/valid.en-de.en
2022-09-01 10:38:16 | INFO | fairseq.data.data_utils | loaded 25014 examples from: ../data/mscoco17/en-de/inverseKD/pre/valid.en-de.de
2022-09-01 10:38:21 | INFO | fairseq.data.data_utils | loaded 25014 examples from: ../data/mscoco17/en-de/inverseKD/pre/valid.image.en-de
2022-09-01 10:38:21 | INFO | fairseq.tasks.translation_immt | ../data/mscoco17/en-de/inverseKD/pre valid en-de 25014 examples
Built pre-trained CNN resnet50 in 0 seconds.
Built pre-trained CNN resnet50 in 1 seconds.
save_dir:../checkpoints/mscoco17/en-de/inverseKD_res_m_l2 2022-09-01 10:38:25 | INFO | fairseq_cli.train | TransformerIMMTModel(
  (encoder): TransformerIMMTEncoder(
    (embed_tokens): Embedding(13448, 128, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerIMMTEncoderLayer(
        (self_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerIMMTEncoderLayer(
        (self_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerIMMTEncoderLayer(
        (self_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerIMMTEncoderLayer(
        (self_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (encoder_image): ImageLocalFeaturesProjector(
      (layers): Sequential(
        (0): View()
        (1): Linear(in_features=2048, out_features=128, bias=True)
        (2): Dropout(p=0.3, inplace=False)
      )
    )
  )
  (decoder): TransformerIMMTDecoder(
    (embed_tokens): Embedding(13448, 128, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerIMMTDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerIMMTDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerIMMTDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerIMMTDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadIMMTAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=128, bias=True)
        (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
)
2022-09-01 10:38:25 | INFO | fairseq_cli.train | model transformer_immt_tiny, criterion LabelSmoothedImmtCrossEntropyCriterion
2022-09-01 10:38:25 | INFO | fairseq_cli.train | num. model params: 3309184 (num. trained: 3309184)
2022-09-01 10:38:25 | INFO | fairseq_cli.train | training on 1 GPUs
2022-09-01 10:38:25 | INFO | fairseq_cli.train | max tokens per GPU = 1024 and max sentences per GPU = None
2022-09-01 10:38:25 | INFO | fairseq.trainer | no existing checkpoint found ../checkpoints/mscoco17/en-de/inverseKD_res_m_l2/checkpoint_last.pt
2022-09-01 10:38:25 | INFO | fairseq.trainer | loading train data for epoch 1
2022-09-01 10:38:25 | INFO | fairseq.data.data_utils | loaded 591753 examples from: ../data/mscoco17/en-de/inverseKD/pre/train.en-de.en
2022-09-01 10:38:25 | INFO | fairseq.data.data_utils | loaded 591753 examples from: ../data/mscoco17/en-de/inverseKD/pre/train.en-de.de
2022-09-01 10:40:26 | INFO | fairseq.data.data_utils | loaded 591753 examples from: ../data/mscoco17/en-de/inverseKD/pre/train.image.en-de
2022-09-01 10:40:26 | INFO | fairseq.tasks.translation_immt | ../data/mscoco17/en-de/inverseKD/pre train en-de 591753 examples
2022-09-01 10:40:29 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2022-09-01 10:41:29 | INFO | train_inner | {"epoch": 1, "update": 0.012, "loss": "12.821", "nll_loss": "12.642", "ppl": "6393.04", "wps": "1542.1", "ups": "1.71", "wpb": "901.5", "bsz": "69", "num_updates": "100", "lr": "0.000200095", "gnorm": "1.653", "clip": "0", "train_wall": "59", "wall": "183"}
2022-09-01 10:42:30 | INFO | train_inner | {"epoch": 1, "update": 0.024, "loss": "9.607", "nll_loss": "9.001", "ppl": "512.43", "wps": "1452.5", "ups": "1.64", "wpb": "883.5", "bsz": "73.7", "num_updates": "200", "lr": "0.00040009", "gnorm": "0.971", "clip": "0", "train_wall": "60", "wall": "244"}
2022-09-01 10:43:28 | INFO | train_inner | {"epoch": 1, "update": 0.036, "loss": "8.606", "nll_loss": "7.786", "ppl": "220.76", "wps": "1542.4", "ups": "1.72", "wpb": "895", "bsz": "69", "num_updates": "300", "lr": "0.000600085", "gnorm": "0.809", "clip": "0", "train_wall": "57", "wall": "302"}
2022-09-01 10:44:28 | INFO | train_inner | {"epoch": 1, "update": 0.048, "loss": "8.033", "nll_loss": "7.125", "ppl": "139.6", "wps": "1503", "ups": "1.64", "wpb": "914.1", "bsz": "73.4", "num_updates": "400", "lr": "0.00080008", "gnorm": "0.79", "clip": "0", "train_wall": "60", "wall": "363"}
2022-09-01 10:45:29 | INFO | train_inner | {"epoch": 1, "update": 0.061, "loss": "7.438", "nll_loss": "6.449", "ppl": "87.38", "wps": "1486.7", "ups": "1.65", "wpb": "898.5", "bsz": "73.5", "num_updates": "500", "lr": "0.00100008", "gnorm": "0.773", "clip": "0", "train_wall": "60", "wall": "423"}
2022-09-01 10:46:29 | INFO | train_inner | {"epoch": 1, "update": 0.073, "loss": "7.037", "nll_loss": "5.991", "ppl": "63.59", "wps": "1473.6", "ups": "1.67", "wpb": "885", "bsz": "71.8", "num_updates": "600", "lr": "0.00120007", "gnorm": "0.806", "clip": "0", "train_wall": "59", "wall": "484"}
2022-09-01 10:47:29 | INFO | train_inner | {"epoch": 1, "update": 0.085, "loss": "6.636", "nll_loss": "5.532", "ppl": "46.27", "wps": "1477.3", "ups": "1.67", "wpb": "883.3", "bsz": "72.8", "num_updates": "700", "lr": "0.00140006", "gnorm": "0.792", "clip": "0", "train_wall": "59", "wall": "543"}
2022-09-01 10:48:30 | INFO | train_inner | {"epoch": 1, "update": 0.097, "loss": "6.197", "nll_loss": "5.03", "ppl": "32.66", "wps": "1435.1", "ups": "1.63", "wpb": "879.5", "bsz": "74.2", "num_updates": "800", "lr": "0.00160006", "gnorm": "0.782", "clip": "0", "train_wall": "60", "wall": "605"}
2022-09-01 10:49:29 | INFO | train_inner | {"epoch": 1, "update": 0.109, "loss": "5.975", "nll_loss": "4.769", "ppl": "27.26", "wps": "1483.5", "ups": "1.69", "wpb": "879.3", "bsz": "71.8", "num_updates": "900", "lr": "0.00180005", "gnorm": "0.836", "clip": "0", "train_wall": "58", "wall": "664"}
2022-09-01 10:50:28 | INFO | train_inner | {"epoch": 1, "update": 0.121, "loss": "5.749", "nll_loss": "4.508", "ppl": "22.75", "wps": "1528.1", "ups": "1.7", "wpb": "899.6", "bsz": "71.5", "num_updates": "1000", "lr": "0.00200005", "gnorm": "0.783", "clip": "0", "train_wall": "58", "wall": "723"}
2022-09-01 10:51:24 | INFO | train_inner | {"epoch": 1, "update": 0.133, "loss": "5.728", "nll_loss": "4.48", "ppl": "22.32", "wps": "1594.5", "ups": "1.78", "wpb": "897.2", "bsz": "67.5", "num_updates": "1100", "lr": "0.00220004", "gnorm": "0.793", "clip": "0", "train_wall": "55", "wall": "779"}
2022-09-01 10:52:23 | INFO | train_inner | {"epoch": 1, "update": 0.145, "loss": "5.411", "nll_loss": "4.113", "ppl": "17.31", "wps": "1535", "ups": "1.71", "wpb": "899.3", "bsz": "71", "num_updates": "1200", "lr": "0.00240004", "gnorm": "0.804", "clip": "0", "train_wall": "58", "wall": "838"}
2022-09-01 10:53:23 | INFO | train_inner | {"epoch": 1, "update": 0.157, "loss": "5.082", "nll_loss": "3.735", "ppl": "13.32", "wps": "1442.8", "ups": "1.65", "wpb": "873.8", "bsz": "73.6", "num_updates": "1300", "lr": "0.00260003", "gnorm": "0.792", "clip": "0", "train_wall": "60", "wall": "898"}
2022-09-01 10:54:24 | INFO | train_inner | {"epoch": 1, "update": 0.17, "loss": "4.986", "nll_loss": "3.621", "ppl": "12.31", "wps": "1458", "ups": "1.65", "wpb": "881.6", "bsz": "73.6", "num_updates": "1400", "lr": "0.00280003", "gnorm": "0.775", "clip": "0", "train_wall": "60", "wall": "959"}
2022-09-01 10:55:24 | INFO | train_inner | {"epoch": 1, "update": 0.182, "loss": "4.96", "nll_loss": "3.588", "ppl": "12.03", "wps": "1502.8", "ups": "1.68", "wpb": "896.2", "bsz": "72.3", "num_updates": "1500", "lr": "0.00300002", "gnorm": "0.763", "clip": "0", "train_wall": "59", "wall": "1018"}
2022-09-01 10:56:21 | INFO | train_inner | {"epoch": 1, "update": 0.194, "loss": "5.034", "nll_loss": "3.67", "ppl": "12.73", "wps": "1570.7", "ups": "1.75", "wpb": "898", "bsz": "68.5", "num_updates": "1600", "lr": "0.00320002", "gnorm": "0.752", "clip": "0", "train_wall": "56", "wall": "1075"}
2022-09-01 10:57:19 | INFO | train_inner | {"epoch": 1, "update": 0.206, "loss": "4.894", "nll_loss": "3.509", "ppl": "11.39", "wps": "1540.9", "ups": "1.73", "wpb": "893.2", "bsz": "69.4", "num_updates": "1700", "lr": "0.00340001", "gnorm": "0.739", "clip": "0", "train_wall": "57", "wall": "1133"}
2022-09-01 10:58:17 | INFO | train_inner | {"epoch": 1, "update": 0.218, "loss": "4.798", "nll_loss": "3.397", "ppl": "10.54", "wps": "1512.3", "ups": "1.71", "wpb": "885.5", "bsz": "70.7", "num_updates": "1800", "lr": "0.00360001", "gnorm": "0.753", "clip": "0", "train_wall": "58", "wall": "1192"}
2022-09-01 10:59:17 | INFO | train_inner | {"epoch": 1, "update": 0.23, "loss": "4.649", "nll_loss": "3.225", "ppl": "9.35", "wps": "1487.7", "ups": "1.68", "wpb": "888", "bsz": "72.2", "num_updates": "1900", "lr": "0.0038", "gnorm": "0.721", "clip": "0", "train_wall": "59", "wall": "1252"}
2022-09-01 11:00:17 | INFO | train_inner | {"epoch": 1, "update": 0.242, "loss": "4.763", "nll_loss": "3.354", "ppl": "10.22", "wps": "1491.1", "ups": "1.68", "wpb": "890.2", "bsz": "72.1", "num_updates": "2000", "lr": "0.004", "gnorm": "0.745", "clip": "0", "train_wall": "59", "wall": "1311"}
2022-09-01 11:01:16 | INFO | train_inner | {"epoch": 1, "update": 0.254, "loss": "4.622", "nll_loss": "3.193", "ppl": "9.15", "wps": "1492.1", "ups": "1.68", "wpb": "890.6", "bsz": "72", "num_updates": "2100", "lr": "0.0039036", "gnorm": "0.698", "clip": "0", "train_wall": "59", "wall": "1371"}
2022-09-01 11:02:15 | INFO | train_inner | {"epoch": 1, "update": 0.266, "loss": "4.715", "nll_loss": "3.3", "ppl": "9.85", "wps": "1535.6", "ups": "1.7", "wpb": "901.7", "bsz": "70.1", "num_updates": "2200", "lr": "0.00381385", "gnorm": "0.693", "clip": "0", "train_wall": "58", "wall": "1430"}
2022-09-01 11:03:14 | INFO | train_inner | {"epoch": 1, "update": 0.278, "loss": "4.572", "nll_loss": "3.135", "ppl": "8.78", "wps": "1498.6", "ups": "1.7", "wpb": "883", "bsz": "70.3", "num_updates": "2300", "lr": "0.00373002", "gnorm": "0.688", "clip": "0", "train_wall": "58", "wall": "1489"}
2022-09-01 11:04:15 | INFO | train_inner | {"epoch": 1, "update": 0.291, "loss": "4.342", "nll_loss": "2.872", "ppl": "7.32", "wps": "1471.9", "ups": "1.64", "wpb": "895.7", "bsz": "73.5", "num_updates": "2400", "lr": "0.00365148", "gnorm": "0.648", "clip": "0", "train_wall": "60", "wall": "1550"}
2022-09-01 11:05:16 | INFO | train_inner | {"epoch": 1, "update": 0.303, "loss": "4.319", "nll_loss": "2.846", "ppl": "7.19", "wps": "1457.7", "ups": "1.63", "wpb": "896.3", "bsz": "74.2", "num_updates": "2500", "lr": "0.00357771", "gnorm": "0.635", "clip": "0", "train_wall": "61", "wall": "1611"}
2022-09-01 11:06:17 | INFO | train_inner | {"epoch": 1, "update": 0.315, "loss": "4.34", "nll_loss": "2.871", "ppl": "7.32", "wps": "1479.3", "ups": "1.65", "wpb": "895.7", "bsz": "72.9", "num_updates": "2600", "lr": "0.00350823", "gnorm": "0.636", "clip": "0", "train_wall": "60", "wall": "1672"}
2022-09-01 11:07:15 | INFO | train_inner | {"epoch": 1, "update": 0.327, "loss": "4.444", "nll_loss": "2.99", "ppl": "7.94", "wps": "1546.4", "ups": "1.73", "wpb": "895.9", "bsz": "68.6", "num_updates": "2700", "lr": "0.00344265", "gnorm": "0.622", "clip": "0", "train_wall": "57", "wall": "1730"}
2022-09-01 11:08:15 | INFO | train_inner | {"epoch": 1, "update": 0.339, "loss": "4.228", "nll_loss": "2.742", "ppl": "6.69", "wps": "1483.4", "ups": "1.65", "wpb": "897.1", "bsz": "72.4", "num_updates": "2800", "lr": "0.00338062", "gnorm": "0.597", "clip": "0", "train_wall": "60", "wall": "1790"}
